# RPG-Encoder vs. Microsoft RPG-ZeroRepo: A Brutal, Honest Comparison

## TL;DR — They Are Not The Same Thing

**Microsoft RPG-ZeroRepo**: A top-down **code generation** framework. Input: natural language description. Output: a complete working repository. Python-only. 14 Microsoft Research authors. ICLR 2026 poster.

**rpg-encoder (this repo)**: A bottom-up **code understanding** tool. Input: existing codebase. Output: a semantic graph for navigation/search. Multi-language. Solo/small team. Community project.

They share the name "RPG" and the graph concept, but they solve **opposite** problems. Comparing them head-to-head is like comparing a GPS navigation system to a map-drawing tool.

---

## 1. The Claims vs. The Evidence

### Microsoft's Claims (Paper 1: arXiv 2509.16198)

| Claim | Verdict |
|-------|---------|
| 81.5% functional coverage (vs Claude Code's 54.2%) | **Plausible but self-evaluated.** RepoCraft is their own benchmark with their own LLM-as-judge evaluation. No independent reproduction. |
| 69.7% pass rate (vs Claude Code's 33.9%) | **Same caveat.** Tests are self-generated, self-evaluated. Claude Code is run without RPG context — apples-to-oranges. |
| 36K LOC generated (3.9x strongest baseline) | **True but misleading.** More LOC != better. Human gold projects have 97K LOC at 81% pass rate — ZeroRepo generates 36K LOC at 69.7%. More code, less correct per line. |
| "Unified and Scalable" | **Partially true.** Python-only. 6 projects. Not tested on any non-Python repository. "Universal" is a stretch. |

### Microsoft's Claims (Paper 2: arXiv 2602.02084 — RPG-Encoder)

| Claim | Verdict |
|-------|---------|
| 93.7% Acc@5 on SWE-bench Verified | **Strong, but with Claude-4.5-Sonnet.** The LLM does heavy lifting. Attribution between RPG-Encoder's graph and the LLM's capability is unclear. |
| 98.5% RepoCraft reconstruction coverage | **Impressive if reproducible.** But RepoCraft is their own benchmark — circular validation risk. |
| 95.7% maintenance cost reduction via topology evolution | **Reasonable** for incremental updates vs full rebuild. This is an expected property of any diff-based system. |

### This Repo's Claims

| Claim | Verdict |
|-------|---------|
| "Implements the RPG-Encoder paper" | **Partially true.** Implements the core concepts (semantic lifting, LCA grounding, 3-level hierarchy, incremental updates, 3-tool interface). But diverges significantly in implementation details. |
| 36 MCP tools | **True.** Verified by code analysis. Comprehensive tooling. |
| 630+ tests | **True.** Verified by local test annotations (`#[test]` count). Solid test coverage for a tool of this scope. |
| 8+ languages | **True.** Tree-sitter bindings for Python, Rust, TypeScript, JavaScript, Go, Java, C, C++ (plus extended PHP, Ruby, Kotlin, Swift, Scala, Bash). |
| Agent-as-lifter (no API key needed) | **True and novel.** Microsoft's implementation requires OpenAI/Azure API calls. This repo uses the connected coding agent. |

---

## 2. Architecture Comparison — The Hard Facts

| Dimension | Microsoft RPG-ZeroRepo | rpg-encoder |
|-----------|----------------------|-------------|
| **Language** | Python (~99%) | Rust (100%) |
| **LOC** | ~2.4 MB Python (estimated 50-80K LOC) | 24,824 LOC Rust |
| **Direction** | NL -> Code (generative) | Code -> Graph -> Navigation (analytical) + Agent-driven code gen with TDD (v0.6.0) |
| **Code parsing** | Python `ast` module (Python files only) | Tree-sitter (8+ languages) |
| **LLM dependency** | **Hard dependency** — every stage calls LLM | **Soft dependency** — agent lifts features interactively |
| **LLM providers** | 10 supported (OpenAI default: gpt-5-mini) | None required (agent IS the LLM) |
| **Graph storage** | In-memory Python dicts -> JSON | On-disk `.rpg/graph.json` with optional zstd compression |
| **Dependency graph** | NetworkX MultiDiGraph (42K byte module) | Custom Rust BTreeMap with edge index |
| **Hierarchy depth** | Fixed 5-level (repo/area/category/subcategory/feature_group/feature) | Flexible 3-level (area/category/subcategory) |
| **Edge types** | COMPOSES, CONTAINS, INHERITS, INVOKES, IMPORTS | Imports, Invokes, Inherits, Composes, Contains, Renders, ReadsState, WritesState, Dispatches, DataFlow |
| **Feature tree** | EpiCoder (1.5M pre-built capabilities) | Generated by connected agent from code |
| **Testing** | **1 test file** (code extraction only) | **630+ tests** across 7 crates |
| **Docker** | Required for code generation | Not required |
| **Embedding model** | FAISS + `infly/inf-retriever-v1` (feature selection) + Qwen3-Embedding-0.6B (eval) | fastembed + BGE-small-en-v1.5 (384-dim) |
| **MCP support** | Listed as dependency, plugin "coming soon" | **Primary interface** — 36 tools over stdio JSON-RPC |
| **Resume/checkpoint** | Yes (15 intermediate files + state JSON) | Yes (graph persists to disk, lifting sessions resumable) |
| **Framework awareness** | None (Python-centric) | TOML-driven paradigm system (React, Next.js, Redux, Django, Spring, etc.) |

---

## 3. What Microsoft Does Better — Honestly

### 3.1 Code Generation Pipeline (Their Main Contribution)

Microsoft's ZeroRepo is a **complete generation system**. It goes from "build me a snake game" to a running repository with tests. rpg-encoder's `rpg-gen` crate (v0.6.0) now has a functional agent-driven pipeline: spec decomposition, interface design, task scheduling with dependency context, an iterative TDD loop (`report_task_outcome` with 5-outcome failure routing and 3-retry limit), signature-level validation, and pre-seeded RPG features. It lacks Docker-based sandboxing (the connected agent executes directly) and the EpiCoder ontology.

**Verdict**: Microsoft still leads on generation maturity (Docker sandboxing, pre-built ontology, formal evaluation), but rpg-encoder's pipeline is now **functional end-to-end** — not a skeleton.

### 3.2 Evaluation Rigor (Within Their Scope)

Microsoft has RepoCraft (6 real-world Python projects), comparison against 7 baselines (Claude Code, ChatDev, MetaGPT, etc.), ablation studies, and scaling analysis. rpg-encoder has self-evaluation with MRR 0.59 on its own codebase and no formal benchmark.

**Verdict**: Microsoft wins on evaluation methodology, even if the benchmark is their own.

### 3.3 Feature Tree Ontology

The EpiCoder Feature Tree with 1.5M pre-built software capabilities across 7 levels is a significant knowledge artifact. It seeds feature selection with domain knowledge that no bottom-up approach can match from scratch.

**Verdict**: Having a pre-built ontology is a real advantage for generation. rpg-encoder doesn't need one (it's analytical), but for generation tasks, this matters.

### 3.4 Academic Credibility

ICLR 2026 poster acceptance. 14 authors from Microsoft Research. Two papers with formal algorithm definitions.

**Verdict**: The academic weight is undeniable.

### 3.5 Benchmark Results (Even If Self-Evaluated)

ZeroRepo's numbers against baselines are compelling:

| Agent | Model | Coverage | Pass/Vote | LOC |
|-------|-------|----------|-----------|-----|
| MetaGPT | o3-mini | 16.6% | 4.5%/10.2% | 225 |
| ChatDev | o3-mini | 18.3% | 2.6%/10.5% | 410 |
| OpenHands | o3-mini | 22.0% | 5.1%/16.9% | 292 |
| Codex CLI | o3-pro | 28.4% | 11.0%/20.0% | 612 |
| Gemini CLI | gemini-2.5-pro | 42.0% | 14.5%/37.9% | 1,485 |
| Claude Code | claude-4-sonnet | 54.2% | 33.9%/52.5% | 10,587 |
| **ZeroRepo** | **o3-mini** | **81.5%** | **69.7%/75.0%** | **23,977** |

Human gold: 81.0% pass rate, 97,820 LOC.

---

## 4. What rpg-encoder Does Better — Honestly

### 4.1 Multi-Language Support (Not Even Close)

Microsoft: Python `ast` module. **Python only.** Period.

rpg-encoder: Tree-sitter with 8+ production languages (Python, Rust, TypeScript, JavaScript, Go, Java, C, C++) plus 6 extended languages. Framework-aware paradigm system handles React/Next.js/Redux/Django/Spring.

**Verdict**: rpg-encoder is **categorically superior** on language support. Microsoft's "universal" claims are invalidated by Python-only parsing.

### 4.2 No External LLM API Required

Microsoft: Every stage calls OpenAI/Azure. Feature selection, refactoring, file design, function design, code generation, failure analysis, commit message generation — all LLM calls. The cost is enormous and undisclosed.

rpg-encoder: The connected coding agent (Claude Code, Cursor) IS the lifter. Zero external API calls. Zero cost beyond the agent you're already paying for.

**Verdict**: rpg-encoder's agent-as-lifter model is a **genuine innovation** that Microsoft hasn't matched.

### 4.3 Engineering Quality

Microsoft: **1 test file.** Public repo history is currently only 3 commits. No CI checks visible. `rpg.py` is 1,760 lines in a single file. `code_gen.py` is 83,891 bytes. No clippy-equivalent.

rpg-encoder: 630+ tests. CI pipeline (fmt + clippy -D warnings + test). Clean crate separation. Deterministic serialization. Schema versioning with semver. Pedantic lints enabled.

**Verdict**: rpg-encoder is **significantly better engineered**. Microsoft's repo feels like research code dumped for paper compliance.

### 4.4 Operational Readiness

Microsoft: Requires Docker, specific container images, provider credentials, and trae-agent vendored from ByteDance. Setup is non-trivial.

rpg-encoder: `npx -y -p rpg-encoder rpg-mcp-server /path/to/repo`. Done. Published on npm. No Docker. No API keys.

**Verdict**: rpg-encoder is **immediately usable**. Microsoft's is a research artifact.

### 4.5 MCP Integration

Microsoft: "An RPG-based plugin for Claude Code is under active development" — announced but not yet released.

rpg-encoder: 36 MCP tools. Working. Tested. Deployed. Used daily.

**Verdict**: Not even a contest.

### 4.6 Framework-Aware Analysis

Microsoft: No framework awareness. Treats all Python code the same.

rpg-encoder: TOML-driven paradigm system detects React, Next.js, Redux, Django, Spring, etc. Creates framework-specific entity kinds (Component, Hook, Page, Layout, Service, Controller). Adds framework-specific edge types (Renders, ReadsState, WritesState, Dispatches). Auto-lifts with paradigm-aware rules.

**Verdict**: rpg-encoder's paradigm system is **unique and valuable**. Nothing comparable exists in ZeroRepo.

### 4.7 Edge Type Richness

Microsoft: 5 edge types (Composes, Contains, Inherits, Invokes, Imports).

rpg-encoder: 10 edge types (Imports, Invokes, Inherits, Composes, Contains, Renders, ReadsState, WritesState, Dispatches, DataFlow). DataFlow edges are inferred from signatures — novel.

**Verdict**: rpg-encoder has a **richer dependency model**.

### 4.8 Incremental Updates (Actually Tested)

Both claim incremental updates. But rpg-encoder has git2 integration, .rpgignore support, drift detection with three-zone routing (Jaccard distance), and feature preservation across rebuilds — all tested.

Microsoft's `generate_detailed_diff()` exists in the encoder module but the test coverage is zero.

**Verdict**: rpg-encoder's incremental story is **more mature and tested**.

---

## 5. Where Both Fall Short — The Uncomfortable Truths

### 5.1 Neither Has Independent Evaluation

- Microsoft evaluates on their own benchmark (RepoCraft) with their own LLM-as-judge.
- rpg-encoder has only self-evaluation (MRR 0.59 on its own codebase).
- **Neither has been independently reproduced or validated by a third party.**

### 5.2 Neither Handles Cross-Language Dependencies

A TypeScript frontend calling a Python backend? A Go service calling a Rust library? Neither handles this. Both are intra-language only.

### 5.3 Neither Has Real-Time IDE Integration

No file watchers. No incremental-as-you-type indexing. Both require explicit commands to update the graph. Neither competes with LSP for real-time developer experience.

### 5.4 The "RPG" Concept Itself Has Limitations

The 3-level (or 5-level) hierarchy is a rigid taxonomic structure. Real codebases have cross-cutting concerns (logging, auth, caching) that don't fit neatly into trees. Neither system handles this well.

### 5.5 Semantic Features Are Only As Good As The LLM

Microsoft calls OpenAI to generate features. rpg-encoder relies on the connected agent. In both cases, feature quality is bounded by LLM capability. Neither has a way to validate or improve features beyond re-running the LLM.

---

## 6. The Numbers That Matter

| Metric | Microsoft RPG-ZeroRepo | rpg-encoder |
|--------|----------------------|-------------|
| **Usable today?** | Requires Docker, Azure, OpenAI API key | `npx rpg-encoder rpg-mcp-server .` |
| **Tests** | 1 file | 630+ |
| **Languages parsed** | 1 (Python) | 8+ |
| **Edge types** | 5 | 10 |
| **MCP tools** | 0 (promised) | 36 (working) |
| **External LLM cost** | Every operation | Zero |
| **Academic papers** | 2 (ICLR accepted) | 0 |
| **GitHub stars** | 361 (as of 2026-02-14) | Lower |
| **Authors** | 14 (Microsoft Research) | Small team |
| **Code generation** | Production pipeline (Docker + TDD) | Agent-driven pipeline (TDD + validation, no Docker) |
| **Benchmark eval** | RepoCraft (6 projects, 7 baselines) | Self-eval only |

---

## 7. Microsoft's RPG Data Model

### Node Structure

```python
@dataclass
class Node:
    id: str                          # UUID-based string
    node_type: Optional[str]         # "repo", "functional_area", "category", etc.
    name: str                        # Display name
    level: Optional[int]             # 0 (repo) through 5 (feature)
    unit: Optional[Tuple]            # Code unit reference
    meta: Optional[NodeMetaData]     # type_name, path, description, content
```

Level-to-type mapping:

| Level | Type |
|-------|------|
| 0 | repo |
| 1 | functional_area |
| 2 | category |
| 3 | subcategory |
| 4 | feature_group |
| 5 | feature |

### Edge Structure

```python
@dataclass
class Edge:
    src: str
    dst: str
    relation: EdgeType  # COMPOSES, CONTAINS, INHERITS, INVOKES, IMPORTS
```

### NodeType Enum

```python
class NodeType(str, Enum):
    DIRECTORY, FILE, CLASS, FUNCTION, METHOD, COMPONENT,
    DATA, INTERFACE, VARIABLE, IMPORT, REPO, MODULE, PACKAGE
```

### RPG Class (1,760 lines)

- `nodes: Dict[str, Node]`
- `edges: List[Edge]`
- `_adjacency: Dict[str, List[str]]` — parent-to-children
- `_parents: Dict[str, str]` — child-to-parent
- `dep_graph: DependencyGraph` — NetworkX-based
- `recalculate_levels_topdown()`, `_update_levels_upwards()`

---

## 8. rpg-encoder's RPG Data Model

### Entity Structure

```rust
pub struct Entity {
    pub id: String,                          // "path/file.rs:name" or "path/file.rs:Class::method"
    pub kind: EntityKind,
    pub name: String,
    pub file: PathBuf,
    pub line_start: usize,
    pub line_end: usize,
    pub parent_class: Option<String>,
    pub semantic_features: Vec<String>,      // ["parse config", "validate tokens"]
    pub feature_source: Option<String>,      // "auto", "llm", or "synthesized"
    pub hierarchy_path: String,              // "Auth/Login/Handlers"
    pub deps: EntityDeps,
    pub signature: Option<Signature>,
}
```

### EntityDeps (18 vectors: 9 forward + 9 reverse)

```rust
pub struct EntityDeps {
    pub imports: Vec<String>,
    pub invokes: Vec<String>,
    pub inherits: Vec<String>,
    pub composes: Vec<String>,
    pub renders: Vec<String>,
    pub reads_state: Vec<String>,
    pub writes_state: Vec<String>,
    pub dispatches: Vec<String>,
    pub data_flows_to: Vec<String>,
    // + 9 reverse vectors (imported_by, invoked_by, etc.)
}
```

### HierarchyNode

```rust
pub struct HierarchyNode {
    pub id: String,                          // "h:Area/Category/Subcategory"
    pub name: String,
    pub grounded_paths: Vec<PathBuf>,        // LCA-computed directories
    pub children: BTreeMap<String, HierarchyNode>,
    pub entities: Vec<String>,
    pub semantic_features: Vec<String>,      // Aggregated from subtree
    pub description: Option<String>,
}
```

### RPGraph

```rust
pub struct RPGraph {
    pub version: String,                    // "2.1.0"
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
    pub base_commit: Option<String>,
    pub metadata: GraphMetadata,
    pub hierarchy: BTreeMap<String, HierarchyNode>,  // V_H
    pub entities: BTreeMap<String, Entity>,           // V_L
    pub edges: Vec<DependencyEdge>,                   // E
    pub file_index: BTreeMap<PathBuf, Vec<String>>,
}
```

---

## 9. Microsoft's Three-Phase Pipeline (Detailed)

### Phase 1: Proposal-Level Planning

**Feature Selection** (FeatureSelectAgent):
- Takes `repository_purpose` text
- FAISS vector DB with `infly/inf-retriever-v1` embeddings
- Exploitation agent (deepen branches) + Exploration agent (discover new areas)
- Self-check validation + missing features identification
- Iterates `select_max_iterations` (default: 2) rounds
- Seeds from 11 predefined top-level categories (workflow, functionality, algorithm, etc.)

**Feature Refactoring** (FeatureRefactorAgent):
- Groups features into Components via LLM
- Validates leaf nodes (detects fabricated nodes, logs "Imagine Rate")
- Requires 4-level paths, rejects subtrees with <20 valid leaves
- Up to 40 iterations

### Phase 2: Implementation-Level Construction

1. **Create Initial RPG**: Components -> hierarchical node trees
2. **File Design**: Raw skeleton + group skeleton -> `RepoSkeleton`
3. **Function Design**: Data flow analysis + base class design + interface design (topological order)
4. **Task Planning**: Split into `TaskBatch` objects, one per file

### Phase 3: Graph-Guided Code Generation

Per-batch TDD loop (up to 5 cycles):
1. Generate tests (trae-agent) -> commit
2. Generate code (trae-agent) -> commit
3. Run pytest inside Docker
4. Analyze: PASS / TEST_ERROR / CODE_ERROR / ENV_ERROR
5. Route to appropriate fix workflow

**Trae-Agent**: ByteDance's vendored coding agent
- Tools: bash, str_replace_based_edit_tool, sequentialthinking, task_done
- Up to 300 steps per invocation
- Docker container: `python-azure-pytest:3.12`

---

## 10. Microsoft's Key Algorithms

### Algorithm 1: Rejection Sampling (Diversity-Aware)

```
Input: Root R, frequencies F, temperature t, sample size S, overlap threshold rho
BaseSample: For each sample, compute frequency-weighted probabilities,
            apply temperature transform, sample node, descend
RejectSample: Retry up to T_max times, accept if overlap <= rho
```

### Algorithm 2: Repository-Specific Subtree Selection

```
For K iterations:
    E_exploit = RetrieveTopK(T, R)              // exploitation
    E_explore = SampleUnvisited(T, V)            // exploration
    C_raw = LLM.Select(E_exploit) UNION LLM.Select(E_explore) UNION LLM.ProposeMissing()
    B* = LLM.SELFCHECK(T', batch)               // consistency validation
    T' = InsertPaths(T', B*)
```

### Algorithm 3: Topological Sort for Implementation Order

Files ordered by import/invocation dependencies. Base classes and utilities designed before consumers.

### Algorithm 4: Iterative TDD with Failure Classification

5-round majority voting distinguishes test errors from code errors from environment errors. Up to 20 remediation attempts.

---

## 11. rpg-encoder's Key Algorithms

### Algorithm 1: LCA-Based Directory Grounding

```
1. Extract parent directories from entity file paths
2. Build prefix trie
3. Walk trie: retain branching nodes (>1 child) and terminal nodes
4. Return minimal LCA set
Complexity: O(n * k) where n = entities, k = avg path depth
```

### Algorithm 2: Drift Detection (Three-Zone)

```
Jaccard distance = 1 - |intersection| / |union|
< 0.3: IGNORE (minor edit, keep features)
0.3-0.7: REVIEW (queue for agent re-routing)
> 0.7: AUTO-ROUTE (needs new hierarchy placement)
```

### Algorithm 3: Auto-Lift with Confidence

```
1. Try TOML-based pattern match
2. If match: analyze structural signals (branches, loops, calls)
3. Confidence:
   - Accept: 0 branches, 0 loops, <=2 calls -> apply directly
   - Review: 1 branch, 3+ calls -> pre-fill for LLM verification
   - Reject: 2+ branches OR any loop -> full LLM lifting
```

### Algorithm 4: Hybrid Embedding Search

```
1. Embed query via BGE-small-en-v1.5
2. Per entity: max-cosine pooling across all feature embeddings
3. Blend: hybrid_score = 0.6 * embedding_rank + 0.4 * lexical_rank
4. Apply diff-aware proximity boost (optional)
```

### Algorithm 5: DataFlow Edge Inference

```
For each Invokes edge (A -> B):
    If B has parameters: add DataFlow A -> B (arg passing)
    If B has return_type: add DataFlow B -> A (return value)
```

### Algorithm 6: Incremental Update from Git

```
1. Detect changes: git diff (committed + staged + unstaged)
2. Filter via .rpgignore and language extensions
3. Re-parse changed files only
4. Merge semantic data from old graph (features, hierarchy_path)
5. Detect drift (Jaccard), queue for re-routing if needed
6. Rebuild edges, resolve dependencies
```

---

## 12. The Papers — Key Facts

### Paper 1: "RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation"

- **arXiv**: 2509.16198 (September 2025)
- **Venue**: ICLR 2026 (poster)
- **Authors**: 14 (Microsoft Research)
- **Core**: RPG as structured planning -> ZeroRepo framework
- **Benchmark**: RepoCraft (6 Python projects, 1,052 tasks)
- **Key result**: 81.5% coverage, 69.7% pass rate (vs Claude Code's 54.2%/33.9%)
- **Formal definition**: G = (N, E) with dual functional/structural semantics

### Paper 2: "Closing the Loop: Universal Repository Representation with RPG-Encoder"

- **arXiv**: 2602.02084 (February 2026)
- **Authors**: 13 (Microsoft Research)
- **Core**: RPG as bidirectional representation (generation + comprehension)
- **Formal definition**: G = (V_H UNION V_L, E_feature UNION E_dep)
- **Key results**: 93.7% Acc@5 on SWE-bench Verified, 98.5% RepoCraft reconstruction
- **Three-phase encoding**: Semantic lifting -> structure reorganization -> artifact grounding
- **Incremental evolution**: 95.7% maintenance cost reduction via commit-level diffs

### Relationship

| Aspect | RPG (Paper 1) | RPG-Encoder (Paper 2) |
|--------|--------------|----------------------|
| Direction | Top-down only (generation) | Bidirectional (generation + comprehension) |
| Input | Natural language specification | Existing source code |
| Graph source | EpiCoder Feature Tree (1.5M capabilities) | Code itself via semantic lifting |
| Primary use | Repository generation from scratch | Understanding, navigation, reconstruction |
| Maintenance | N/A (one-shot generation) | Incremental via commit diffs |
| Tool interface | Graph-guided localization | SearchNode + FetchNode + ExploreRPG |

---

## 13. rpg-encoder's 36 MCP Tools

### Navigation (6 tools)
1. `search_node` — Hybrid embedding + lexical search
2. `fetch_node` — Entity metadata + source (field projection)
3. `explore_rpg` — Dependency traversal (up/down/both)
4. `rpg_info` — Graph statistics
5. `context_pack` — Search + fetch + explore in one call
6. `impact_radius` — BFS reachability analysis

### Building (2 tools)
7. `build_rpg` — Index codebase
8. `update_rpg` — Incremental update from git

### Lifting Protocol (6 tools)
9. `get_entities_for_lifting` — Batch entities for agent analysis
10. `submit_lift_results` — Agent returns semantic features
11. `lifting_status` — Progress dashboard
12. `finalize_lifting` — Aggregate features
13. `get_files_for_synthesis` — File-level features for synthesis
14. `submit_file_syntheses` — Agent returns file-level summaries

### Hierarchy (4 tools)
15. `build_semantic_hierarchy` — Domain discovery prompts
16. `submit_hierarchy` — Agent assigns 3-level paths
17. `get_routing_candidates` — Entities pending routing (drift detection)
18. `submit_routing_decisions` — Agent routes with stale-decision protection

### Code Generation (8 tools)
19. `init_generation` — Initialize session
20. `get_feature_tree` — Spec decomposition
21. `submit_feature_tree` — Agent refines spec
22. `get_interfaces_for_design` — Interface design prompts
23. `submit_interface_design` — Agent designs interfaces
24. `get_tasks_for_generation` — Dependency-ordered tasks with context enrichment
25. `submit_generated_code` — Agent submits code
26. `validate_generation` — Signature comparison against plan

### Generation Management (5 tools)
27. `generation_status` — Progress dashboard
28. `report_task_outcome` — TDD iteration routing (pass/test_failure/code_error/test_error/env_error)
29. `reset_generation` — Clear session
30. `retry_failed_tasks` — Retry failed tasks
31. `finalize_generation` — Complete, build RPG, pre-seed features

### Utilities (5 tools)
32. `reconstruct_plan` — Topological batching
33. `reload_rpg` — Reload from disk
34. `find_paths` — Dependency paths between entities
35. `slice_between` — Code slice extraction
36. `plan_change` — Impact analysis + ordering

---

## 14. Microsoft's Tech Stack

| Library | Purpose |
|---------|---------|
| `openai` (>=2.14.0) | Default LLM provider |
| `anthropic` (>=0.75.0) | Claude models |
| `google-genai` (>=1.24.0) | Gemini models |
| `networkx` (>=3.0) | Dependency graph |
| `faiss-cpu` (>=1.7.0) | Vector similarity search |
| `sentence-transformers` (>=5.2.0) | Embeddings |
| `torch` (>=2.9.1) | Model inference |
| `transformers` (>=4.57.3) | Model loading |
| `tree-sitter` (0.21.3) | Code parsing (listed, Python `ast` used in practice) |
| `tiktoken` (>=0.12.0) | Token counting |
| `docker` (>=7.1.0) | Container management |
| `pydantic` (>=2.0.0) | Structured output schemas |
| `llama-index` (0.11.22) | RAG infrastructure |
| `scikit-learn` (>=1.0.0) | Clustering, outlier detection |
| `mcp` (1.12.2) | Model Context Protocol |

**Default model**: `gpt-5-mini-20250807`

**10 LLM providers**: OpenAI, Azure OpenAI, Anthropic, Google, DeepSeek, vLLM, OpenRouter, Ollama, Doubao (ByteDance), OpenAI-compatible

---

## 15. rpg-encoder's Tech Stack

| Library | Purpose |
|---------|---------|
| `tree-sitter` + 15 language bindings | Multi-language parsing |
| `fastembed` 5.8.1 | BGE-small-en-v1.5 embeddings |
| `rmcp` 0.14.0 | MCP server framework |
| `git2` | Git integration for change detection |
| `tokio` | Async runtime |
| `serde` / `serde_json` | Serialization |
| `rayon` | Parallel parsing |
| `zstd` | Optional graph compression |
| `strsim` | Drift detection (Jaccard distance) |
| `kodama` | Hierarchical clustering |
| `globset` / `ignore` | File filtering |
| `toon-format` 0.4.1 | LLM-optimized serialization |
| `indicatif` | Progress bars |
| `sha2` | Content verification |

**No LLM provider required** — connected agent is the lifter.

---

## 16. Final Verdict

### What Microsoft Does That rpg-encoder Doesn't (Yet)

1. **Docker-sandboxed execution** and pre-built EpiCoder ontology (1.5M capabilities) — rpg-encoder now has TDD and iterative repair but executes via the connected agent, not a Docker container
2. **Formal benchmarking** against real baselines — no comparable evaluation exists here
3. **Academic credibility** — ICLR 2026, two papers, 14 authors
4. **Pre-built feature ontology** (1.5M EpiCoder capabilities)

### What rpg-encoder Does That Microsoft Doesn't

1. **Multi-language support** (8+ vs Python-only) — this alone disqualifies Microsoft's "universal" claims
2. **Zero external LLM cost** — agent-as-lifter is a genuine innovation
3. **Working MCP server** with 36 tools — Microsoft promises one, this repo ships one
4. **Framework awareness** — paradigm system for React, Next.js, Redux, Django, Spring
5. **Engineering quality** — 630+ tests vs 1, CI/CD, pedantic lints, deterministic serialization
6. **Operational readiness** — npm install and go

### The Honest Assessment

**Microsoft has the better paper.** They define the problem formally, evaluate rigorously (within their scope), and demonstrate impressive generation results.

**rpg-encoder is the better tool.** It's usable, tested, multi-language, framework-aware, and doesn't require an OpenAI API key. It's a tool someone can use today. Microsoft's is a research artifact that requires Docker and significant setup to reproduce.

**The gap to close:** Formal evaluation. Without a benchmark — even a small one — rpg-encoder relies on "trust me, it works." The paper's 93.7% SWE-bench claim (even if inflated by LLM capability) is something that can't be countered with "MRR 0.59 self-evaluated."

**The gap they need to close:** Multi-language, MCP integration, engineering quality, and operational readiness. Their Python-only limitation is a major constraint for any "universal" claim.

---

## Sources

- [Microsoft RPG-ZeroRepo on GitHub](https://github.com/microsoft/RPG-ZeroRepo)
- [RPG Paper (arXiv 2509.16198)](https://arxiv.org/abs/2509.16198)
- [RPG-Encoder Paper (arXiv 2602.02084)](https://arxiv.org/abs/2602.02084)
- [Hugging Face Paper Page](https://huggingface.co/papers/2509.16198)
- [RPG-Encoder Project Page](https://ayanami2003.github.io/RPG-Encoder/)
